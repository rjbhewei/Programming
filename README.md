# Heracles: Improving Resource Efficiency at Scale

### 摘要

类似于 *websearch* 这种面向用户、延迟敏感的服务, 在日常低流量的情况的下未能充分的利用计算资源，很少在生产性服务商为其他的任务重新利用这些资源，因为争夺共享资源会让延迟导致毛刺，以致违背了延迟敏感敏感人物的 *SLO* (service-level objectives)

### 介绍

公有云和私有云框架允许我们持续增长成千上万台服务器的大型数据中心的负载数量，云服务的商业模式强调降低基础架构成本,,因而需要继续扩大服务器的最大化利用率

### 共享资源的干扰

当两个或者多个工作负载同时在一台服务器上执行的时候，它们会竞争共享资源，这个章节我们回顾下主要的干扰源、可用的隔离机制和动态管理的动机

在一台服务器上最主要的共享资源是在一个或者多个cpu卡槽上的核心，我们不能简单的使用cgroups cpuset机制静态绑定核心给LC服务和BE任务混布的场景，当类似搜索这种面向用户的服务会出现负载毛刺，它们需要所有可用的核区面对吞吐的需求而不是导致违背SLO，同样我们不能简单的分配高优先级给LC服务和依靠操作系统的调度任务对核心的分配，通常的调度算法如linux的CFS算法，有漏洞，当LC服务和BE任务混布的时候以至于频繁的导致LC服务违背SLO，实时调度算法(eg:FIFO),会工作不饱和导致很低的利用率，
在英特尔核心上可用的超线程技术导致进一步的并发症，例如超线程执行BE任务能干扰LC超线程指令带宽、共享L1和L2级缓存，和TLBs

大量研究表明，在共享资源中的不可控的最后一级缓存干扰(LLC)对混部是有很大影响的。为了解决这个问题，英特尔最近介绍在服务器芯片上LLC缓存分区，这个功能叫做缓存分配技术(CAT),

1. 内存带宽


	大部分LC服务都是操作着很大的数据集，这个导致不能够CPU的CACHE是存放不下的,因而，在高负载的时候频繁的访问内存，使得内存带宽压力增大，以致于会对内存带宽比较敏感，尽管有了很多对内存带宽隔离上面的重要研究，但在商用芯片上还没有硬件隔离机制，在一些多socket服务器上，可以通过NUMA管道隔离不同的工作负载，但这种方法约束了内存的容量分配和寻址，内存带宽缺乏硬件支持，导致工作负载动态管理隔离复杂并且效率约束
	
2. 网络带宽

	数据中心负载扩展了应用增加网络流量，很多数据中心采用丰富的拓扑结构来均分网络流量来避免网络汇中路由拥塞现象，这里有多种网络协议，用来优先处理LC服务的短消息再处理BE任务的大消息，在一个服务器内，拥塞问题可能发生在网络入口也可能发生在网络出口，当一个BE任务导致网络拥塞，我们可以调整cpu核心的分配直到网络限流机制触发，在流量出口方向，我们可以用linux操作系统的交通管控(Traffic control)机制来提供对LC服务的网络带宽的保证，使得它们的信息优先于BE任务的信息，网络带块的交通管控必须能够随着系统负载被动态管理，另外静态网络流量优先级，可能会导致资源利用率不高甚至出现饿死现象
	
3. 能耗(power)
	
	在混部场景下,能耗是一个额外的干扰源，所有现代的多核芯片都有一些形式上的动态超频，比如英特尔芯片中的Turbo Boost以及AMD芯片中的Turbo Core，在能耗有余量的情况下这些技术提升了处理器芯片比标称频率的更高的频率，因而，LC任务使用的核心的时钟频率不仅仅取决于它自己的负载而且取决于运行在相同槽位上面的BE任务的强度，换句话说，LC任务可能会因为混部任务导致性能频繁的意外下降，这个干扰可以通过每个核心的动态电压频率缩放来减少( This interference can be mitigated with per-core dynamic voltage frequency scaling)，做为运行BE任务的核可以降低它们的频率使得LC任务保持正常的频率，静态策略会以最低的频率运行所有的BE任务从而确保LC任务没有能耗方面的限制，但是这个方法严重的惩罚了绝大部分的BE任务，大部分BE任务没有配置
	
4. 跨资源干扰
	
	混部的一个严重的挑战是跨资源干扰，一个BE任务可能会引发上面讨论过的所有共享资源的干扰，类似的，很多LC服务都会对多种资源干扰敏感，因而不能能够只去管理一种干扰资源，所有潜在的资源需要被监控和小心的隔离，另外干扰源是彼此互相交互的，例如，LLC的争夺可能会导致两种类型的任务都去需要更多的内存带宽从而可能导致瓶颈，类似的，一个任务注意到了网络拥塞问题从而企图使用数据压缩的方式可能会导致cpu和功耗方面的争夺，理论上，干扰可能的数量会是干扰源数据的平方，导致这成了一个非常困难的问题
	
### 干扰表征和分析	

本章节描述共享资源对延迟敏感服务的干扰特点

1. 延迟敏感的工作负载

	我们使用三个谷歌线上的延迟敏感的服务做为介绍，websearch 是线上web搜索服务中的一个查询服务部分，他是一个有一定规模的工程，通过大型的fan-out架构，提供了严格的延迟SLO且很高的吞吐量，拥有上千个用于查询搜索索引分片的子节点，对于这些叶子节点的SLO 99%的延迟在几十毫秒，websearch 负载的增加使用的是真实的用户查询中的匿名的追踪
	
	websearch 因为会存储很多的索引分片在内存中，因而有很高的内存使用，同时它还有适度的内存带宽需求，在负载100%的时候会占用40%的可用内存带宽，有很大一部分的索引侵入丢失在LLC上，这里有一个小但是重要的指令工作集和数据集在LLC中，它需要计算得分和排序搜索的hits从而有一定的cpu计算，，但是它不需要很大数量的网络带宽，为了这个研究，为了能够混部BE任务，我们使用较小份的内存在搜索服务上

	ml_cluster是一个独立的服务，用机器学习的技术来做实时集群文本分析，很多谷歌应用服务使用ml_cluster给集群分配文本信息的特征/片段，ml_cluster通过以前的离线训练模型把文本存放在集群中，这个模型因为性能的考虑主要存放在内存中，ml_cluster的SLO是 95%的延迟保证在几十毫秒，ml_cluster 采用的是捕获生产服务中真实的匿名请求追踪
	
	对比于websearch, ml_cluster需要更多的内存带宽(在峰值的时候需要60%的内存带宽)，但是只需要很少的cpu计算(整体来看cpu的能耗也是很低的)，同时对网络带宽的需求也是很低的，ml_cluster一个有趣的现象是它的每个请求都有少量的缓存足迹，但是存在很多重要的请求，就会转化成为一个很大数量的缓存压力，从而蔓延到对内存的压力，这个反应到我门的分析中是内存带宽随着负载是一个超线性的增长关系
	
	memkeyval 是一个内存中的key-value的存储服务，类似于 memchached，memkeyval被用于很多谷歌的后端web服务的缓存系统，其他的大型web服务公司如facebook和twiter广泛采用的是memcached，memkeyval明显的减少了每个请求处理耗时，对比于websearch,在峰值需要每秒几十万的请求指令导致它需要极高的吞吐量，因而任何请求的处理耗时必须很快，这SLO 是时延非常的低，99%的延迟在百来微秒的时延，memkeyval负载的增加方式跟ml_cluster一样
	
	在负载峰值，memkeyval会被网络带宽限制，尽管每个请求采用的是很小数量的网络协议，在高的请求率下导致memkeyval成为cpu密集型计算，相比之下，内存带宽的需求要比较小(在最大负载的时候使用20%的内存带宽)，request请求从内存中简单的接受value并且放入response中发送给网络，memkeyval既有对LLC静态工作集指令也有每个请求数据集
	
2. 表征方法

	为了了解这些服务对共享资源干扰的敏感性，我们运行上面的三个LC服务用一个合成的基线来衡量在每个隔离的资源下，虽然这些事在一个单独的服务节点下面的实验，不过这里可以远端控制负载的增长所以仍然会有大量的网络流量，我们为每个LC任务在多个不同的负载点下重复多个表征并且记录托管情况下尾延迟的影响
	
	使用的是google生产环境下的服务器，规格为:
	
	* 双叉槽, Intel Xeons based on the Haswell architecture
	* 每个物理cpu有比较多的核心
	* 每个核心的标称频率是2.3GHz and 2.5MB of LLC
	* 芯片有硬件支撑用于对LLC做分区(英特尔的CAT)
	
	我们进行如下的表征实验:
	
	* 核心
	
		正如我们在$2中的讨论，我们不能让LC和BE任务共享同一个逻辑核心(独立的超线程)，这会让操作系统调度引入几十毫秒的延迟毛刺，因此我们聚焦于使用不同的超线程的能力去运行在相同的物理核上，我们描述的实现时对LC任务共同定位超线程的影响，这个实验捕获超线程干扰的影响下限，更多的计算和内存使用微基准将会为多核资源对抗着LC超线程(eg:执行单元)和L1，L2缓存空间，因此如果这个实现表现出尾延迟很高的影响，我们可以得出通过超线程共享核心不是一个实际的选择的结论
			
	* LLC
		
		这个实验来测试LLC的干扰者对其的干扰，在特定的负载下给LC任务绑定足够的核心用于满足它的SLO并且绑定在同一个CPU插槽上面的剩余核心的干扰者传输着大量的数组阵列，我们使用数组阵列大小分别为占据LLC四分之一，一半和几乎所有的LLC的阵列，这些配置表现为LLC(small),LLC(med),LLC(big)
	
	* 内存带宽

		内存带宽的干扰方式跟LLC的干扰方式比较相似，使用明显非常大的数组阵列进行流式传输，我们使用numactl确保内存干扰者和LC任务分配到相同的一个或者多个CPU槽位并且所有的内存通道都会受到压力
		
	* 网络带宽流量

		我们使用iperf，一种开源TCP流式传输基准,使外出的网络流量饱和，除了一个核心以外的所有内核都提供给LC任务，因而我们考虑从多个客户端连接到LC服务，我们产生干扰以许多低带宽“小鼠”流的形式，增加网络流量的干扰也可以使用少许“大象”流，但是这些流会被TCP拥塞控制有效的节流，而LC很多的“小鼠”流不会受到影响
		
	* 能耗

		为了表征一个能耗干扰者对延迟的影响，相同的核心划分用来作为增加对LLC和内存带宽的干扰，而不是运行一个内存侵入干扰者，使用的是一个cpu能耗病毒程序，该程序设计为灰给所有的核心压力，导致高的能耗导致降低cpu的核心频率
		
	* 操作系统隔离
	
		为了完整性，我们运行BE任务和LC任务仅仅使用操作系统可用的隔离机制来评估整体的影响，我分别用linux的容器技术运行两个工作任务并且设置BE任务是一种低的优先级运行，这种调度策略通过CFS使用共享参数，相比于LC任务，BE任务接受很少量的共享资源，没有任何资源隔离的机制就是使用这种方式，BE任务使用的是goole的brain程序，我们会在将来在继续讨论
		
3. 干扰分析

	图一三种LC负载的尾延迟表现出干扰微基线的影响，在表中每一行展示的是在某种负载下LC任务和混部微基准下的尾延迟情况，只有在尾延迟小于SLO的100%的情况下这些干扰的影响才能够被接受，我们使用全彩色的代码来标示时延，用红/黄来标示违反了SLO延迟
	
	通过brain程序的运行的那行记录，我们理解注意到当前的操作系统的隔离机制是不足以让LC和BE进行混部的，即使在低负载的情况下，BE任务在共享资源上创造足够的压力会导致这三种LC任务的SLO被违背，很大的贡献在于操作系统允许两个任务运行在相同的核心上和运行在相同的超线程上，进一步加重了干扰，尾延迟最后超过了SLO的300%，建议干扰管制的集群管理，比如Paragon和Bubble-Up，讲不会允许这种情况混部，为了能够暴力的达成这种任务混部，我们不仅仅需要做到不允许不同的任务运行在相同的核心或者超线程上，我们还需要更强的隔离机制
	
	LC任务会因为个别共享资源的变化而被干扰的敏感性，例如，memkeyval对网络干扰相当的敏感，但websearch 和 ml_cluster基本没有受到影响，websearch对LLC(small)和LLC(med)的干扰均不敏感，但不能说对memkeyval 和 ml_cluster也如此，另外负载的改变干扰的影响，ml_cluster在负载小于50%的时候能够容忍LLC(med)的干扰，但是在高负载的时候会有很严重的影响，这些观察促动需要隔离机制动态的管理，以适应不同的负载变化和不同的任务，任何静态的策略都会太保守(遗失混部的机会)或者过于乐观(导致违背任务的SLO)
	
	我们现在分别讨论每个LC任务，为了去了解他们对特殊资源的需求
	
	* websearch

		这个任务会有少量的对CPU缓存的足迹，并且LLC(small)和LLC(med)干扰不会影响到尾延迟。然而，对于LLC(big)的干扰会有很严重的影响，这种退化是由于两个因素导致的，第一个，在这种特别的芯片中LLC的包容性在高的LLC干扰下会导致丢失指令工作集，第二个，争夺LLC也会严重的导致内存带宽压力，websearch对于饱和的内存带宽干扰会特别的敏感。在websearch的负载增加的时，LLC和内存带宽的干扰会下降，在高的负载时候，websearch使用更多的核心同时干扰器会给更少的核心，因此websearch能够更好的保护它的共享资源。
		
		websearch直到高负载的时候都能够适应超线程的干扰，这表明核心直到80%的负载之前对spinloop和websearch有足够的指令发布带宽，由于spinloop仅仅侵入寄存器，它不会对L1和L2缓存产生干扰，但是由于超线程干扰者有最小可能性的影响，更多的干扰器会导致更大的性能问题，因此超线程的干扰在实践中需要被避免，随着更多的核心执行能耗病毒会使得websearch较低利用率的时候使得能耗干扰有一个重要的干扰，如预期的，由于websearch对带宽的低需求导致网络干扰器不会影响到websearch
		
	* ml_cluster

		ml_cluster对于LLC(small)干扰敏感大小，由于每个请求工作集小但是重要，这个体现在LLC(small)70%负载和LLC(med)50%负载的时候它会有一个很大的跳跃，在LLC(big)的干扰下ml_cluster主要延迟严重退化，ml_cluster也会对内存带宽的干扰敏感，ml_cluster直到高负载之前对于主要在低的负载(见websearch的解释)情况下适应超线程的干扰，表明它在高的负载时仅仅达到高的指令发布率，ml_cluster对于能耗的干扰只有较小的影响，因为对比于websearch cpu计算密集程度更小，最后，ml_cluster根本不受网络干扰的影响。
		
	* memkeyval

		由于明显的更严格延迟SLO，memkeyval对所有类型的干扰都会敏感，在高负载的时候，memkeyval在小的工作集加起来会对LLC(small)敏感，在面对LLC(med)的干扰时出现了两次延迟峰值，对此峰值在小的负载时从缓存中干扰器移除指令引发的，当memkeyval在高负载的时候获得足够的核心，他避免了这些驱逐，第二个峰值时在高的负载的时候，当干扰起干扰每个请求工作集，在高水准的LLC干扰下，memkeyval不能够达到SLO，尽管memkeyval只有很低的内存带宽需求，但是他对内存带宽干扰有很大的影响，讽刺的是，少数来自memkeyval的内存请求被内存干扰器覆盖
		
		除了高负载之下，memkeyval对超线程干扰器不敏感，相比之下，它是计算密集对能耗干扰非常敏感，memkeyval会消耗大量的网络带宽，因此对于竞争网络流量会有很高的敏感性，即使在小的负载时候，他完全被大量的小的("小鼠")干扰流量超限并无法满足SLO
	
	
	
	
	
	
	
	

	
