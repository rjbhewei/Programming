# Heracles: Improving Resource Efficiency at Scale

###摘要
类似于 *websearch* 这种面向用户、延迟敏感的服务, 在日常低流量的情况的下未能充分的利用计算资源，很少在生产性服务商为其他的任务重新利用这些资源，因为争夺共享资源会让延迟导致毛刺，以致违背了延迟敏感敏感人物的 *SLO* (service-level objectives)

###介绍
公有云和私有云框架允许我们持续增长成千上万台服务器的大型数据中心的负载数量，云服务的商业模式强调降低基础架构成本,,因而需要继续扩大服务器的最大化利用率

###共享资源的干扰
当两个或者多个工作负载同时在一台服务器上执行的时候，它们会竞争共享资源，这个章节我们回顾下主要的干扰源、可用的隔离机制和动态管理的动机

在一台服务器上最主要的共享资源是在一个或者多个cpu卡槽上的核心，我们不能简单的使用cgroups cpuset机制静态绑定核心给LC服务和BE任务混布的场景，当类似搜索这种面向用户的服务会出现负载毛刺，它们需要所有可用的核区面对吞吐的需求而不是导致违背SLO，同样我们不能简单的分配高优先级给LC服务和依靠操作系统的调度任务对核心的分配，通常的调度算法如linux的CFS算法，有漏洞，当LC服务和BE任务混布的时候以至于频繁的导致LC服务违背SLO，实时调度算法(eg:FIFO),会工作不饱和导致很低的利用率，
在英特尔核心上可用的超线程技术导致进一步的并发症，例如超线程执行BE任务能干扰LC超线程指令带宽、共享L1和L2级缓存，和TLBs

大量研究表明，在共享资源中的不可控的最后一级缓存干扰(LLC)对混部是有很大影响的。为了解决这个问题，英特尔最近介绍在服务器芯片上LLC缓存分区，这个功能叫做缓存分配技术(CAT),

1. 内存带宽


	大部分LC服务都是操作着很大的数据集，这个导致不能够CPU的CACHE是存放不下的,因而，在高负载的时候频繁的访问内存，使得内存带宽压力增大，以致于会对内存带宽比较敏感，尽管有了很多对内存带宽隔离上面的重要研究，但在商用芯片上还没有硬件隔离机制，在一些多socket服务器上，可以通过NUMA管道隔离不同的工作负载，但这种方法约束了内存的容量分配和寻址，内存带宽缺乏硬件支持，导致工作负载动态管理隔离复杂并且效率约束
	
2. 网络带宽

	数据中心负载扩展了应用增加网络流量，很多数据中心采用丰富的拓扑结构来均分网络流量来避免网络汇中路由拥塞现象，这里有多种网络协议，用来优先处理LC服务的短消息再处理BE任务的大消息，在一个服务器内，拥塞问题可能发生在网络入口也可能发生在网络出口，当一个BE任务导致网络拥塞，我们可以调整cpu核心的分配直到网络限流机制触发，在流量出口方向，我们可以用linux操作系统的交通管控(Traffic control)机制来提供对LC服务的网络带宽的保证，使得它们的信息优先于BE任务的信息，网络带块的交通管控必须能够随着系统负载被动态管理，另外静态网络流量优先级，可能会导致资源利用率不高甚至出现饿死现象
	
3. 能耗(power)
	
	在混部场景下,能耗是一个额外的干扰源，所有现代的多核芯片都有一些形式上的动态超频，比如英特尔芯片中的Turbo Boost以及AMD芯片中的Turbo Core，在能耗有余量的情况下这些技术提升了处理器芯片比标称频率的更高的频率，因而，LC任务使用的核心的时钟频率不仅仅取决于它自己的负载而且取决于运行在相同槽位上面的BE任务的强度，换句话说，LC任务可能会因为混部任务导致性能频繁的意外下降，这个干扰可以通过每个核心的动态电压频率缩放来减少( This interference can be mitigated with per-core dynamic voltage frequency scaling)，做为运行BE任务的核可以降低它们的频率使得LC任务保持正常的频率，静态策略会以最低的频率运行所有的BE任务从而确保LC任务没有能耗方面的限制，但是这个方法严重的惩罚了绝大部分的BE任务，大部分BE任务没有配置
	
4. 跨资源干扰
	
	混部的一个严重的挑战是跨资源干扰，一个BE任务可能会引发上面讨论过的所有共享资源的干扰，类似的，很多LC服务都会对多种资源干扰敏感，因而不能能够只去管理一种干扰资源，所有潜在的资源需要被监控和小心的隔离，另外干扰源是彼此互相交互的，例如，LLC的争夺可能会导致两种类型的任务都去需要更多的内存带宽从而可能导致瓶颈，类似的，一个任务注意到了网络拥塞问题从而企图使用数据压缩的方式可能会导致cpu和功耗方面的争夺，理论上，干扰可能的数量会是干扰源数据的平方，导致这成了一个非常困难的问题
	
	
	
	
	
	
	
	
	
	

	
